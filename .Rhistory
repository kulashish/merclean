;
}
unlist(m.s)
unlist(ir)
unlist(m.s)[unlist(ir)==FALSE]
mgsub(unlist(m.s)[unlist(ir)==FALSE], "CODE", x)
x <- c(x, "DILLARDS H2342 ALJDS")
x
m <- gregexpr(p, x)
m
m.s <- regmatches(x, m)
m.s
ir <- lapply(m.s, '%in%', valid_words)
mgsub(unlist(m.s)[unlist(ir)==FALSE], "CODE", x)
m.s
m
grepl(p, r)
grepl(p, x)
x
m.s
unlist(m.s)[unlist(ir)==FALSE]
grepl(p, x) & !unlist(ir) == FALSE
grepl(p,x)
unlist(ir)
ir
lapply(ir, function(x) any(x==FALSE))
unlist(lapply(ir, function(x) any(x==FALSE)))
grepl(p,x) & unlist(lapply(ir, function(x) any(x==FALSE)))
mgsub(unlist(m.s)[unlist(ir)==FALSE], "CODE", x[which(grepl(p,x) & unlist(lapply(ir, function(x) any(x==FALSE)))==TRUE)])
?gsub
?mgsub
i <- grepl(p,x) & unlist(lapply(ir, function(x) any(x==FALSE)))
i
x[i]
x[which(i==TRUE)]
x
m.s
x <- c(x, "DILLARDS ABCD AB234")
m <- gregexpr(p, x)
m.s <- regmatches(x, m)
m.s
ir <- lapply(m.s, '%in%', valid_words)
unlist(m.s)[unlist(ir)==FALSE]
unique(unlist(m.s)[unlist(ir)==FALSE])
cat("strings to replace", "10")
str <- unique(unlist(m.s)[unlist(ir)==FALSE])
str
i <- grepl(p,x) & unlist(lapply(ir, function(x) any(x==FALSE)))
i
x[i] <- mgsub(str, "CODE", x[i])
x
split(x, cut(x, n, labels=F))
?ceil
min(10,2)
i
length(i==TRUE)
x[i==TRUE]
x
i==TRUE
sum(i==TRUE)
x <- gsub("CO*", "BORE", x)
x
x <- gsub("\\<BO*\\>", "CORE", x)
x
x <- gsub("\\<BO.*\\>", "CORE", x)
x
x <- gsub("\\bBA.*\\b", "CORE", x)
x
substr("ashish", length("ashish")-2, length("ashish"))
substr("ashish", 4,5)
substr("ashish", 5, 6)
substr("ashish", length("ashish")-1, length("ashish"))
length("ashish")
nchar("ashish")
nchar("how are you")
substr("ashish", nchar("ashish")-1, nchar("ashish"))
cities
library(geo)
library(maps)
data(us.cities)
us.cities
head(us.cities)
head(us.cities$country.etc)
length(us.cities$country.etc)
length(unique(us.cities$country.etc))
regmatches("how are you", gregexpr("[[:alnum:]]{2}$", "how are you"))
substr("ashish", nchar("ashish")-1, nchar("ashish"))
substr("ashish", nchar("ashish")-1, nchar("ashish")) <- STATE
substr("ashish", nchar("ashish")-1, nchar("ashish")) <- 'STATE'
x
x <- c("GREEN TR    CLARKSVILLE IN", "MALL IN     LOUISVILLE  KY", "MERRITT     MERRITT ISL ZA")
data(us.cities)
us.states <- unique(us.cities$country.etc)
matches <- regexpr(" [[:alpha:]]{2}$", x)
matches
strings <- regmatches(x, matches)
strings
strings %in% us.states
trim(strings) %in% us.states
install.packages("stringr")
strings
str_trim(strings)
library(stringr)
str_trim(strings)
str_trim(strings) %in% us.states
x
isreplace <- str_trim(strings) %in% us.states
x[isreplace == TRUE] <- gsub("[[:alpha:]]{2}$", "STATE", x[isreplace==TRUE])
x
head(us.cities)
length(us.cities)
us.cities
length(us.cities)
nrow(us.cities)
head(us.cities)
"CLARKSVILLE" %in% us.cities$name
"um" %in% us.states
"UM" %in% us.states
x
isreplace
us.states
x <- c(x, "DILLARDS - 0172 CHESAPEAKE VA~~XXXXX~~XXXXXXXXXXXXXXXX~~XXXXX~~0~~~~NUM")
matches <- regexpr(" [[:alpha:]]{2}$", x)
matches
strings <- regmatches(x, matches)
strings
isreplace <- str_trim(strings) %in% us.states
isreplace
strings <- rep(" ", length(x))
strings
strings[matches!=-1] <- regmatches(x, matches)
strings
isreplace <- str_trim(strings) %in% us.states
isreplace
?read.csv
us.cities
library(maps)
data(us.cities)
us.cities
head(us.cities)
us.cities$name
cities.list <- lapply(us.cities$name, strsplit, '\\W+', perl=T)
cities.vec <- unlist(cities.list)
head(cities.vec)
cat(cities.vec, file='us_cities.txt', sep='\n')
cat('"', cities.vec, '"', file='us_cities.txt', sep='\n')
cities.list <- lapply(cities.list, dQuote)
head(cities.list)
head(unlist(cities.list))
cities.list <- lapply(us.cities$name, strsplit, '\\W+', perl=T)
cities.vec <- unlist(cities.list)
head(cities.vec)
cities.list <- lapply(cities.vec, dQuote)
head(cities.list)
head(unlist(cities.vec))
head(unlist(cities.list))
cat(cities.list, file='us_cities.txt', sep='\n')
cat(unlist(cities.list), file='us_cities.txt', sep='\n')
length(us.cities$name[1])
length(us.cities$name[2])
head(us.cities$name)
sum(us.cities$name[2])
length(strsplit(us.cities$name[2], '\\W+', perl=T))
us.cities$name[2]
strsplit(us.cities$name[2], '\\W+', perl=T)
length(unlist(strsplit(us.cities$name[2], '\\W+', perl=T)))
max(lapply(us.cities$name, function(x) length(unlist(strsplit(x, '\\W+', perl=T))))))
max(lapply(us.cities$name, function(x) length(unlist(strsplit(x, '\\W+', perl=T)))))
max(unlist(lapply(us.cities$name, function(x) length(unlist(strsplit(x, '\\W+', perl=T))))))
us.cities
data(us.county)
?maps
??maps
data(county)
install.packages("noncensus")
library(noncensus)
data(combined_areas)
combined_areas
data(corebased_area)
data(corebased_areas)
corebased_areas
data(counties)
counties
counties$county_name
counties.list <- lapply(counties$county_name, strsplit, '\\W+', perl=T)
counties.vec <- unlist(counties.list)
head(counties.vec)
tail(counties.vec)
counties.freq <- table(counties.vec)
head(counties.freq)
cat('Word\tFREQ', counties.freq, file='us_counties.txt', sep='\n')
counties.freq <- paste(names(counties.freq), counties.freq, sep="\t")
cat('Word\tFREQ', counties.freq, file='us_counties.txt', sep='\n')
counties.freq <- paste(names(counties.freq), counties.freq, sep=",")
cat('Word,FREQ', counties.freq, file='us_counties.txt', sep='\n')
counties.freq <- paste(names(counties.freq), counties.freq, sep=",")
counties.freq <- table(counties.vec)
counties.freq <- paste(names(counties.freq), counties.freq, sep=",")
cat('Word,FREQ', counties.freq, file='us_counties.txt', sep='\n')
us.cities$name
gsub(' [[:alpha:]]{2}$', '', us.cities$name)
places.list <- gsub(' [[:alpha:]]{2}$', '', us.cities$name)
counties$county_name
places.list <- c(places.list, counties$county_name)
places.list
length(places.list)
length(us.cities$name)
length(counties)
length(counties$county_name)
paste(names(result.freq.list.sorted), result.freq.list.sorted, sep="\t")
paste(names(result.freq.list.sorted), result.freq.list.sorted, sep="\t")
corebased_areas
corebased_areas$name
gsub(', [[:alpha:]]{2}', '', corebased_areas$name)
places.list <- c(places.list, gsub(', [[:alpha:]]{2}', '', corebased_areas$name))
length(places.list)
combined_areas
combined_areas$name
combined <- gsub(', [[:upper:]-]+', '', combined_areas$name)
combined
strsplit("Youngstown-Warren", "\\W+")
places.list <- c(places.list, combined)
length(places.list)
data(noncenssus)
data(noncensus)
places.vec <- unlist(places.list)
places.freq <- table(places.vec)
places.freq.table <- paste(names(places.freq), places.vec, sep=",")
cat('Word,FREQ', places.freq.table, file='us_places.txt', sep='\n')
places.vec
places.words <- lapply(places.list, strsplit, '\\W+', perl=T)
places.words.vec <- unlist(places.words)
places.words.freq <- table(places.words.vec)
places.words.freq.str <- paste(names(places.words.freq), places.words.freq, sep=',')
cat('Word\tFREQ', places.words.freq.str, file='us_places.txt', sep='\n')
us_cities <- read.csv('us_cities', header=F, stringsAsFactors = F)
us_cities <- read.csv('us_cities.txt', header=F, stringsAsFactors = F)
us_cities
head(us_cities)
places.list <- c(places.list, us_cities$V1)
places.words <- lapply(places.list, strsplit, '\\W+', perl=T)
places.words.vec <- unlist(places.words)
places.words.freq <- table(places.words.vec)
places.words.freq.str <- paste(names(places.words.freq), places.words.freq, sep=',')
cat('Word,FREQ', places.words.freq.str, file='us_places.txt', sep='\n')
places.list
places.words <- lapply(places.list, strsplit, '\\W+', perl=T)
head(places.words)
places.words.vec <- unlist(places.words)
head(places.words.vec)
places.words.freq <- table(places.words.vec)
head(places.words.freq)
tail(places.words.freq)
places.words.sorted <- sort(places.words.freq, decreasing = T)
places.words.sorted
us_cities <- read.csv('us_cities.txt', header=F, stringsAsFactors = F)
places.list <- gsub(' [[:alpha:]]{2}$', '', us.cities$name)
places.list <- c(places.list, counties$county_name)
places.list <- c(places.list, gsub(', [[:alpha:]]{2}', '', corebased_areas$name))
combined <- gsub(', [[:upper:]-]+', '', combined_areas$name)
places.list <- c(places.list, combined)
us_cities <- read.csv('us_cities.txt', header=F, stringsAsFactors = F)
places.list <- c(places.list, us_cities$V1)
places.words <- lapply(places.list, strsplit, '\\W+', perl=T)
places.words.vec <- unlist(places.words)
places.words.freq <- table(places.words.vec)
places.words.sorted <- sort(places.words.freq, decreasing = T)
places.words.freq.str <- paste(names(places.words.sorted), places.words.sorted, sep=',')
cat('Word,FREQ', places.words.freq.str, file='us_places.txt', sep='\n')
?gsub
agrep("food", "whole foods")
agrep("dillards", "some transaction at dillard")
agrep("dillards", "some transaction at dillard") <- "merchant"
agrep("dillards", "some transaction at dillard", value=T)
agrep("dillards", strsplit("some transaction at dillard", "\\W+", perl=T), value=T)
strsplit("some transaction at dillard", "\\W+", perl=T)
unlist(strsplit("some transaction at dillard", "\\W+", perl=T))
agrep("dillards", unlist(strsplit("some transaction at dillard", "\\W+", perl=T)), value=T)
x <- c("some transaction at dillard", "another one at dillard's", "one more at dilards", "and last one at dilard")
lapply(x, strsplit, "\\W+", perl=T)
unlist(lapply(x, strsplit, "\\W+", perl=T))
?strsplit
unlist(lapply(x, strsplit, "[[:space:]]", perl=T))
agrep("dillards", unlist(lapply(x, strsplit, "[[:space:]]", perl=T)), value=T)
agrep("dillards", unlist(lapply(x, strsplit, "[[:space:]]", perl=T)), value=T, max.distance=2)
library(qdap)
mgsub(agrep("dillards", unlist(lapply(x, strsplit, "[[:space:]]", perl=T)), value=T, max.distance=2), "MER", x)
x <- c("a transaction at dillard's", "another one at walmrt")
mgsub(agrep(c("dillards", "walmart"), unlist(lapply(x, strsplit, "[[:space:]]", perl=T)), value=T, max.distance=2), "MER", x)
unlist(lapply(x, strsplit, "[[:space:]]", perl=T))
lapply(c('dillards', 'walmrt'), agrep, unlist(lapply(x, strsplit, "[[:space:]]", perl=T)), value=T, max.distance=2)
unlist(lapply(c('dillards', 'walmrt'), agrep, unlist(lapply(x, strsplit, "[[:space:]]", perl=T)), value=T, max.distance=2))
x <- c(x, "another transaction at dillars")
x <- c(x, "one more at dillars")
unlist(lapply(c('dillards', 'walmrt'), agrep, unlist(lapply(x, strsplit, "[[:space:]]", perl=T)), value=T, max.distance=2))
unique(unlist(lapply(c('dillards', 'walmrt'), agrep, unlist(lapply(x, strsplit, "[[:space:]]", perl=T)), value=T, max.distance=2)))
patterns <- read.csv('dillards_patterns.csv', stringsAsFactors=F, header=T)
head(patterns)
patterns <- read.csv('dillards_patterns.csv', stringsAsFactors=F, header=T)
head(patterns)
?read.table
?grepl
rep(1, 5)
rep('TRUE', 5)
rep(TRUE, 5)
?predict
library(tau)
library(itertools)
library(qdap)
library(maps)
library(stringr)
source("cleanup_header.R")
data.source <- read.table(file="kohl.txt", sep='|', quote="", comment.char="", numerals="no.loss", col.names = c('transaction_id', 'description', 'container', 'merchant'), stringsAsFactors = F)
words.freq.corpus       <- read.csv('freq_words_corpus.txt', header = F, stringsAsFactors = F)
words.merchant          <- read.csv('merchant_words.txt', header = T, stringsAsFactors = F)
word.classes            <- read.csv('word_classes.csv', header = T)
valid_words             <<- c(words.freq.corpus$V2, as.character(words.merchant$Word), as.character(word.classes$replace))
remove(words.freq.corpus)
data.source$clean_description <- mysub(word.classes$pattern, word.classes$replace, word.classes$status, data.source$description)
View(data.source$clean_description)
data.source$clean_description <- mysub(word.classes$pattern, word.classes$replace, word.classes$status, data.source$description)
word.classes            <- read.csv('word_classes.csv', header = T)
data.source$clean_description <- mysub(word.classes$pattern, word.classes$replace, word.classes$status, data.source$description)
View(data.source$clean_description)
word.classes            <- read.csv('word_classes.csv', header = T)
data.source$clean_description <- mysub(word.classes$pattern, word.classes$replace, word.classes$status, data.source$description)
View(data.source$clean_description)
words <- readLines(system.file("stopwords", "english.dat", package = "tm"))
data(us.cities)
us.states <<- unique(us.cities$country.etc)
data.source$clean_description <-  preprocess(m, words)
source("cleanup_header.R")
data.source$clean_description <-  preprocess(m, words)
library(tau)
install.packages('tau')
library(tau)
data.source$clean_description <-  preprocess(m, words)
data.source$clean_description <-  preprocess(data.source, words)
data.source$clean_description <- mysub(word.classes$pattern, word.classes$replace, word.classes$status, data.source$clean_description)
View(data.source$clean_description)
data.source <- read.table(file="kohl.txt", sep='|', quote="", comment.char="", numerals="no.loss", col.names = c('transaction_id', 'description', 'container', 'merchant'), stringsAsFactors = F)
data.source$clean_description <-  preprocess(data.source, words)
View(data.source$clean_description)
data.source$clean_description <- mysub(word.classes$pattern, word.classes$replace, word.classes$status, data.source$clean_description)
View(data.source$clean_description)
data.source <- read.table(file="kohl.txt", sep='|', quote="", comment.char="", numerals="no.loss", col.names = c('transaction_id', 'description', 'container', 'merchant'), stringsAsFactors = F)
data.source$clean_description <-  preprocess(data.source, words)
word.classes            <- read.csv('word_classes.csv', header = T)
data.source$clean_description <- mysub(word.classes$pattern, word.classes$replace, word.classes$status, data.source$clean_description)
View(data.source$clean_description)
version
gsub("\\<[[:digit:]]{4}[[:alpha:]]{1,2}\\>", "4D12A", "KOHL'S DEPT STRS KOHL’S DEPT STRS CHG PYMT")
?read.table
mgsub('tj', 'tjmax', 'tjasddsf')
library(qdap)
mgsub('tj', 'tjmax', 'tjasddsf')
mgsub('\\<tj\\>', 'tjmax', 'tjasddsf')
mgsub('\\<tj\\>', 'tjmax', 'tj asddsf')
mgsub('\\<tj\\>', 'tjmax', ' tj asddsf')
mgsub('tj', 'tjmax', 'tj asddsf')
mgsub('\\<tj\\>', 'tjmax', c('tj asddsf', 'tjasdgd')
)
mgsub('tj', 'tjmax', c('tj asddsf', 'tjasdgd'))
mgsub('[0-9]+', 'num', c('123 asddsf', '123asdgd'))
gsub('tj', 'tjmax', c('tj asddsf', 'tjasdgd'))
gsub('\\<tj\\>', 'tjmax', c('tj asddsf', 'tjasdgd'))
?mgsub_div
?mgsub
mgsub('<tj>', 'tjmax', c('tj asddsf', 'tjasdgd')
)
paste0("\\<", x, "\\>")
mgsub(c("\\<tj\\>"), 'tjmax', c('tj asddsf', 'tjasdgd')
)
mgsub(c("\\<tj\\>", "\\<dj\\>"), 'tjmax', c('tj asddsf', 'tjasdgd'))
mgsub(c("\\<tj\\>", "\\<dj\\>"), 'tjmax', c('tj asddsf', 'tjasdgd', "asdsd tj adaad"))
gsub('\\<tj\\>', 'tjmax', c('tj asddsf', 'tjasdgd'))
gsub('\\btj\\b', 'tjmax', c('tj asddsf', 'tjasdgd'))
?cbind
data <- read.csv('d:/Personal/PhD/Speech to text/syllabified.txt', header=F)
data.words.list <- lapply(data[,1], strsplit, '\\W+', perl=TRUE)
head(data[,1])
data[,1] <- as.character(data[,1])
data.words.list <- lapply(data[,1], strsplit, '\\W+', perl=TRUE)
data.words.vec <- unlist(data.words.list)
freq <- table(data.words.vec)
freq.sorted <- sort(freq, decreasing=T)
freq.sorted.table <- paste(names(freq.sorted), freq.sorted, sep="\t")
freq.df <- data.frame(syl=names(freq.sorted), freq=freq.sorted)
View(freq.df)
?ggplot
library(ggplot2)
qplot(data=data.words.vec, geom='histogram')
words.df <- data.frame(data.words.vec)
qplot(data=words.df, geom='histogram')
qplot(data=words.df, geom='histogram', x=words.df[,1])
qplot(data=freq.df, geom='point', x=freq.df[,1], y=freq.df[,2])
freq.df[,1] <- factor(freq.df[,1], levels=freq.df[,1])
qplot(data=freq.df, geom='point', x=freq.df[,1], y=freq.df[,2])
qplot(data=freq.df, geom='line', x=freq.df[,1], y=freq.df[,2])
qplot(data=freq.df, geom='smooth', x=freq.df[,1], y=freq.df[,2])
qplot(data=freq.df, geom='point', x=freq.df[,1], y=freq.df[,2])
data <- read.csv('d:/Personal/PhD/Speech to text/syllabified.txt', header=F)
data.words.list <- lapply(data[,1], strsplit, '\\W+', perl=TRUE)
data[,1] <- as.character(data[,1])
data.words.list <- lapply(data[,1], strsplit, '\\W+', perl=TRUE)
data.words.vec <- unlist(data.words.list)
freq <- table(data.words.vec)
freq.sorted <- sort(freq, decreasing=T)
freq.df <- data.frame(syl=names(freq.sorted), freq=freq.sorted)
freq.df[,1] <- factor(freq.df[,1], levels=freq.df[,1])
qplot(data=freq.df, geom='point', x=freq.df[,1], y=freq.df[,2])
qplot(data=freq.df, geom='point', x=freq.df[,1], y=freq.df[,2], xlab=c('syllable'), ylab=c('frequency'))
keewords <- c('jcp', 'jcpeny')
desc1 <- 'asdc jcp aadmg'
desc2 <- 'fdsdfsjcp dfsf'
gregexpr
?gregexpr
x <- c('asdc jcp aadmg', 'fdsdfsjcp dfsf')
pattern <- patterns[1]
patterns <- c('jcp', 'jcpeny')
pattern <- patterns[1]
matches           <- gregexpr(pattern, x)
matches
pattern   <- paste0("\\<", pattern, "\\>")
matches   <- gregexpr(pattern, x)
matches
matches.strings   <- regmatches(x, matches)
matches.strings
matches.index     <- grepl(pattern, x)
matches.index
paste0(matches.strings, '_', tag)
tag <- 'mer'
paste0(matches.strings, '_', tag)
?regmatches
?gsub
?mgsub
library(qdap)
?mgsub
matches.index
patterns <- c('jcp', 'jcpeny')
x <- c('asdc jcp aadmg', 'fdsdfsjcp dfsf')
pattern <- patterns[1]
pattern           <- paste0("\\<", pattern, "\\>")
matches           <- gregexpr(pattern, x)
matches.strings   <- regmatches(x, matches)
matches.index     <- grepl(pattern, x)
matches.replace   <- paste0(matches.strings, '_', tag)
mgsub(matches.strings[matches.index], matches.replace[matches.index], x)
mgsub(matches.strings[matches.index], matches.replace[matches.index], x[matches.index])
patterns <- c('jcp', 'jcpeny')
x <- c('asdc jcp aadmg', 'fdsdfsjcp dfsf')
pattern <- patterns[1]
pattern           <- paste0("\\<", pattern, "\\>")
mer_tagger_single <- function(pattern, x, tag) {
pattern           <- paste0("\\<", pattern, "\\>")
matches           <- gregexpr(pattern, x)
matches.strings   <- regmatches(x, matches)
matches.index     <- grepl(pattern, x)
matches.replace   <- paste0(matches.strings, '_', tag)
mgsub(matches.strings[matches.index], matches.replace[matches.index], x[matches.index])
}
mer_tagger <- function(patterns, x, tag) {
lapply(patterns, mer_tagger_single, x, tag)
}
mer_tagger(patterns, x, 'mer')
patterns <- paste0("\\<", patterns, "\\>")
patterns
mer_tagger_single <- function(pattern, x, tag) {
matches           <- gregexpr(pattern, x)
matches.strings   <- regmatches(x, matches)
matches.index     <- grepl(pattern, x)
matches.replace   <- paste0(matches.strings, '_', tag)
mgsub(matches.strings[matches.index], matches.replace[matches.index], x[matches.index])
}
mer_tagger <- function(patterns, x, tag) {
patterns    <- paste0("\\<", patterns, "\\>")
pattern.reg <- paste(patterns, collapse="|")
mer_tagger_single(pattern.reg, x, tag)
#  lapply(patterns, mer_tagger_single, x, tag)
}
mer_tagger(patterns, x, 'mer')
mer_tagger_single <- function(pattern, x, tag) {
matches           <- gregexpr(pattern, x)
matches.strings   <- regmatches(x, matches)
matches.index     <- grepl(pattern, x)
matches.replace   <- paste0(matches.strings, '_', tag)
x[matches.index]  <- mgsub(matches.strings[matches.index], matches.replace[matches.index],
x[matches.index])
}
mer_tagger <- function(patterns, x, tag) {
patterns    <- paste0("\\<", patterns, "\\>")
pattern.reg <- paste(patterns, collapse="|")
mer_tagger_single(pattern.reg, x, tag)
#  lapply(patterns, mer_tagger_single, x, tag)
}
mer_tagger(patterns, x, 'mer')
mer_tagger_single <- function(pattern, x, tag) {
matches           <- gregexpr(pattern, x)
matches.strings   <- regmatches(x, matches)
matches.index     <- grepl(pattern, x)
matches.replace   <- paste0(matches.strings, '_', tag)
x[matches.index]  <- mgsub(matches.strings[matches.index], matches.replace[matches.index],
x[matches.index])
return(x)
}
mer_tagger <- function(patterns, x, tag) {
patterns    <- paste0("\\<", patterns, "\\>")
pattern.reg <- paste(patterns, collapse="|")
mer_tagger_single(pattern.reg, x, tag)
#  lapply(patterns, mer_tagger_single, x, tag)
}
mer_tagger(patterns, x, 'mer')
